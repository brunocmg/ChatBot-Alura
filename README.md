# ğŸ¤– ChatBot com Gemini - Alura

Projeto desenvolvido para estudo de **InteligÃªncia Artificial Generativa** utilizando a biblioteca **google-genai**.  
O chatbot se conecta aos modelos **Gemini** do Google, permitindo interaÃ§Ãµes personalizadas com histÃ³rico de conversas e diferentes estilos de resposta.

---

## ğŸ¯ Objetivo
Explorar a API de IA generativa do Google para:
- Criar um chatbot interativo em Python.
- Configurar **system instructions** para controlar o comportamento do modelo.
- Manter histÃ³rico de conversas.
- Executar comandos em loop com entrada do usuÃ¡rio.

---

## ğŸ›  Tecnologias Utilizadas
- **Python 3.11+**
- **google-genai** (`pip install google-genai`)
- **Google Colab** (ou qualquer ambiente Python)
- **Google Gemini API**

---

## ğŸ“‚ Estrutura de Pastas
```
ChatBot-Alura/
â”œâ”€â”€ chatbot.ipynb (Notebook com a implementaÃ§Ã£o do chatbot)
â”œâ”€â”€ requirements.txt (DependÃªncias do projeto)
â””â”€â”€ README.md (DocumentaÃ§Ã£o do projeto)
```

---

## ğŸš€ Como Executar o Projeto

### 1ï¸âƒ£ Clonar o repositÃ³rio
```bash
git clone https://github.com/brunocmg/ChatBot-Alura.git
```

### 2ï¸âƒ£ Acesse a pasta do projeto
```bash
cd ChatBot-Alura
```

### 3ï¸âƒ£ Instalar dependÃªncias
```bash
pip install -r requirements.txt
```

### ConteÃºdo do requirements.txt:
`google-genai`

### 4ï¸âƒ£ Configurar a API Key do Google
No Google Colab ou ambiente local, adicione:

```bash
import os
from google.colab import userdata  # Apenas no Colab

os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')
```
Ou, no terminal:
```bash
export GOOGLE_API_KEY="SUA_API_KEY"
```

ğŸ’¡ Exemplo de Uso

Listar modelos disponÃ­veis
```
from google import genai

client = genai.Client()

for model in client.models.list():
    print(model.name)
```
Criar chatbot bÃ¡sico
```
modelo = "gemini-2.0-flash"
chat = client.chats.create(model=modelo)

resposta = chat.send_message("Oi, tudo bem?")
print(resposta.text)
```
Chat com system instruction
```
from google.genai import types

chat_config = types.GenerateContentConfig(
    system_instruction="VocÃª Ã© um assistente pessoal e sempre responde de forma sucinta."
)

chat = client.chats.create(model=modelo, config=chat_config)

resposta = chat.send_message("O que Ã© computaÃ§Ã£o quÃ¢ntica?")
print(resposta.text)
```
Loop interativo de chat
```
prompt = input("Esperando prompt: ")

while prompt != "fim":
    resposta = chat.send_message(prompt)
    print("Resposta:", resposta.text, "\n")
    prompt = input("Esperando prompt: ")
```
HistÃ³rico de Conversa
```
print(chat.get_history())
```
Exemplo com comportamento sarcÃ¡stico
```
chat_config_2 = types.GenerateContentConfig(
    system_instruction="VocÃª Ã© um assistente pessoal e sempre responde de forma muito sarcÃ¡stica."
)

chat_2 = client.chats.create(model=modelo, config=chat_config_2)
resposta = chat_2.send_message("O que Ã© computaÃ§Ã£o quÃ¢ntica?")
print(resposta.text)
```

ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins educacionais e de estudo de IA generativa.
